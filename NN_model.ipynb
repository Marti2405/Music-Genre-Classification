{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras import regularizers\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(x):\n",
    "    return tf.nn.leaky_relu(x, alpha=0.2)\n",
    "\n",
    "input_shape = 300\n",
    "output_shape = 6\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(500, activation='tanh', input_shape=(300,)))\n",
    "model.add(layers.Dense(250, activation='tanh'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(output_shape, activation='softmax')) \n",
    "\n",
    "sgd = optimizers.SGD(learning_rate=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_folder = 'VectorsBalanced_Max'\n",
    "X_train = np.load('Data/'+ vector_folder +'/X_train.npy')\n",
    "Y_train = np.load('Data/'+ vector_folder +'/Y_train.npy')[:, [0, 1, 2, 3, 4, 5]]\n",
    "X_test = np.load('Data/'+ vector_folder +'/X_test.npy')\n",
    "Y_test = np.load('Data/'+ vector_folder +'/Y_test.npy')[:, [0, 1, 2, 3, 4, 5]]\n",
    "X_validation = np.load('Data/'+ vector_folder +'/X_validate.npy')\n",
    "Y_validation = np.load('Data/'+ vector_folder +'/Y_validate.npy')[:, [0, 1, 2, 3, 4, 5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=10, batch_size=32, validation_data=(X_validation, Y_validation))\n",
    "\n",
    "# Plotting the training and validation loss values\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "\n",
    "# Adding title and labels to the plot\n",
    "plt.title('Model Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "SAVE = False\n",
    "if SAVE:\n",
    "    model.save('my_model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "# Convert one-hot encoded vectors back to categorical values\n",
    "Y_test_categorical = np.argmax(Y_test, axis=1)\n",
    "Y_pred_categorical = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "\n",
    "# Create a confusion matrix\n",
    "cm = confusion_matrix(Y_test_categorical, Y_pred_categorical)\n",
    "\n",
    "# Visualize the confusion matrix using seaborn and matplotlib\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges', xticklabels=['pop','rap', 'rock', 'r&b', 'country' , 'others'], yticklabels=['pop','rap', 'rock', 'r&b', 'country', 'others'])\n",
    "plt.ylabel('True', fontsize=20)\n",
    "plt.xlabel('Predicted', fontsize=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have predicted values stored in 'Y_pred_categorical' and true labels stored in 'Y_test_categorical'\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(Y_test_categorical, Y_pred_categorical)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(Y_test_categorical, Y_pred_categorical, average=None)  # You can choose 'micro', 'macro', 'weighted', or 'samples' as per your requirement\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(Y_test_categorical, Y_pred_categorical, average=None)  # You can choose 'micro', 'macro', 'weighted', or 'samples' as per your requirement\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "# F1-Score\n",
    "f1 = f1_score(Y_test_categorical, Y_pred_categorical, average=None)  # You can choose 'micro', 'macro', 'weighted', or 'samples' as per your requirement\n",
    "print(f\"F1-Score: {f1}\")\n",
    "\n",
    "\n",
    "\n",
    "# Labels for the classes\n",
    "classes = ['pop','rap', 'rock', 'r&b', 'country', 'others']\n",
    "\n",
    "num_colors = 10\n",
    "\n",
    "# Create the colormap\n",
    "cmap = plt.get_cmap('Oranges')\n",
    "\n",
    "# Generate the array of colors\n",
    "colors = [cmap(i / num_colors) for i in range(num_colors)]\n",
    "\n",
    "# Plotting Precision, Recall, and F1-Score\n",
    "x = np.arange(len(classes))\n",
    "width = 0.2\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width, precision, width, label='Precision', color=colors[5])\n",
    "rects2 = ax.bar(x, recall, width, label='Recall', color=colors[8])\n",
    "rects3 = ax.bar(x + width, f1, width, label='F1-Score', color=colors[9])\n",
    "\n",
    "ax.set_xlabel('Metrics')\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Performance Metrics by Class')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(classes)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
